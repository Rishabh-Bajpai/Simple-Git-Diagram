PORT=5000
FLASK_DEBUG=False

# OpenAI / LLM Configuration
LLM_API_KEY=your_LLM_API_KEY_here
LLM_BASE_URL=http://localhost:1234/v1
LLM_MODEL_NAME=your_model_name_here

# GitHub Configuration
# Pptional: providing your own GitHub PAT increases rate limits from 60/hr to 5000/hr
GITHUB_PAT=your_github_pat_here

# Security
SECRET_KEY=generate_a_secure_random_key_here
